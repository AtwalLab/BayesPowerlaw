

<!doctype html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>BayesPowerlaw &#8212; BayesPowerlaw 0.1 documentation</title>
    <link rel="stylesheet" href="../_static/bizstyle.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript" src="../_static/bizstyle.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <meta name="viewport" content="width=device-width,initial-scale=1.0">
    <!--[if lt IE 9]>
    <script type="text/javascript" src="_static/css3-mediaqueries.js"></script>
    <![endif]-->
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="nav-item nav-item-0"><a href="../index.html">BayesPowerlaw 0.1 documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="index.html" accesskey="U">Module code</a> &#187;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <h1>Source code for BayesPowerlaw</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">scipy.special</span> <span class="k">import</span> <span class="n">zeta</span>
<span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="k">import</span> <span class="n">newton</span>
<span class="kn">import</span> <span class="nn">scipy</span> <span class="k">as</span> <span class="nn">sp</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="k">import</span> <span class="n">uniform</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>


<div class="viewcode-block" id="bayes"><a class="viewcode-back" href="../documentation.html#BayesPowerlaw.bayes">[docs]</a><span class="k">class</span> <span class="nc">bayes</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;This function fits the data to powerlaw distribution and outputs the exponent</span>
<span class="sd">    using Bayesian inference (markov chain monte carlo metropolis-hastings algorithm). </span>
<span class="sd">    If the data consists of mixture more than 1 powerlaws, if specified the function will identify the mixture of exponents </span>
<span class="sd">    as well as the weights each exponent carries.</span>

<span class="sd">    parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data: (list or np.array of numbers) </span>
<span class="sd">        An array of data from the powerlaw that is being fitted here y=x^(-gamma)/Z.</span>
<span class="sd">        All values must be integers or floats from 1 to infinity.</span>

<span class="sd">    gamma_range: ([float&gt;1,float&lt;10])</span>
<span class="sd">        The first value in the list indicates the lowest possible exponent, which will be used to start the algorithm. </span>
<span class="sd">        The second value is the largest possible exponent. The algorithm will reject any exponent values higher than that.</span>
<span class="sd">        Default is [1.01,6.0], since exponent of 1 and lower is mathematically invalid, and exponents above 6 are rare.</span>

<span class="sd">    xmin: (int or float &gt;=1)</span>
<span class="sd">        The lowest value from the data included in the powerlaw fit. </span>
<span class="sd">        Default value is &quot;None&quot;, in which case the minimum value observed in the data is used.</span>
<span class="sd">    </span>
<span class="sd">    xmax: (int or float &gt;= xmin)</span>
<span class="sd">        The highest value from the data included in the powerlaw fit. </span>
<span class="sd">        Default value is &quot;None&quot;, in which case the maximum value observed in the data is used.</span>
<span class="sd">        To set xmax to infinity use xmax=np.infty.</span>
<span class="sd">    </span>
<span class="sd">    discrete: (bool) </span>
<span class="sd">        Whether or not the powerlaw is discrete or continuous.</span>
<span class="sd">        Default True, in which case powerlaw is assumed to be discrete.</span>
<span class="sd">        The distinction is important when estimating partition function Z.</span>

<span class="sd">    niters: (int) </span>
<span class="sd">        Number of MCMC iterations performed. The default is 10000.</span>
<span class="sd">    </span>
<span class="sd">    sigma: ([float&gt;0,float&gt;0])</span>
<span class="sd">        Standard deviation of the sampling step size during MCMC for both gamma (first value) and weight (second value).</span>
<span class="sd">        Samples are taken from a gaussian distribution with a mean of zero.</span>
<span class="sd">        Default value is 0.05 for both, which is seen to perform with good efficiency.</span>

<span class="sd">    sigma_burn: ([float&gt;0,float&gt;0])</span>
<span class="sd">        Standard deviation of the sampling step size during MCMC burn in for both gamma (first value) and weight (second value).</span>
<span class="sd">        Samples are taken from a gaussian distribution with a mean of zero.</span>
<span class="sd">        Default value is 1.0 for both, which quickly travels to a correct value range.</span>
<span class="sd">    </span>
<span class="sd">    burn_in (int):</span>
<span class="sd">        Number of MCMC iterations performs during burn in. </span>
<span class="sd">        The results from burn in are discarded from a final posterior distribution.</span>
<span class="sd">        The default is 1000.</span>

<span class="sd">    prior: (string)</span>
<span class="sd">        Prior type for performing Bayesian inference. Possible values:</span>
<span class="sd">        &#39;jeffrey&#39; : derived Jeffrey&#39;s prior for fitting powerlaw distributions (default).</span>
<span class="sd">        &#39;flat&#39;    : flat prior within the specified gamma range.</span>
<span class="sd">    </span>
<span class="sd">    mixed: (int&gt;0) </span>
<span class="sd">        Number of distinct powerlaws the dataset is thought to consist of. Default is 1.</span>

<span class="sd">    fit: (bool)</span>
<span class="sd">        Whether or not to perform fitting while creating the object.</span>
<span class="sd">        Not necessary if only desired to plot a power law with now fit.</span>
<span class="sd">        Default True.</span>

<span class="sd">    attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    n: </span>
<span class="sd">        Sample size of the data.</span>
<span class="sd">        (int&gt;5)</span>

<span class="sd">    params:</span>
<span class="sd">        Number of parameters fitted (mixed*2-1), that is number of exponents (mixed) + number of weights (mixed-1),</span>
<span class="sd">        where the last weight is 1-[weights].</span>
<span class="sd">        (int)</span>

<span class="sd">    niters:</span>
<span class="sd">        Number of iterations in the main MCMC algorithm. </span>
<span class="sd">        Scales with number of parameters (niters x params).</span>
<span class="sd">        (int)</span>

<span class="sd">    burn:</span>
<span class="sd">        Number of iterations in the burn in MCMC algorithm. </span>
<span class="sd">        Scales with number of parameters (burn_in x params).</span>
<span class="sd">        (int)</span>

<span class="sd">    gammas:</span>
<span class="sd">        An array of 10000 gamma values within the given gamma_range for plotting prior.</span>
<span class="sd">        (1D np.array)</span>

<span class="sd">    weight:</span>
<span class="sd">        An array of 100 weight values from 0 to 1 for plotting prior.</span>
<span class="sd">        (1D np.array)</span>

<span class="sd">    sigma_g: </span>
<span class="sd">        Standard deviation of the sampling step size during MCMC for gamma.</span>
<span class="sd">        (float&gt;0)</span>

<span class="sd">    sigma_w: </span>
<span class="sd">        Standard deviation of the sampling step size during MCMC for weight.</span>
<span class="sd">        (float&gt;0)</span>

<span class="sd">    sigma_burn_g: </span>
<span class="sd">        Standard deviation of the sampling step size during MCMC burn in for gamma.</span>
<span class="sd">        (float&gt;0)</span>

<span class="sd">    sigma_burn_w: </span>
<span class="sd">        Standard deviation of the sampling step size during MCMC burn in for weight.</span>
<span class="sd">        (float&gt;0)</span>

<span class="sd">    prior_gamma:</span>
<span class="sd">        An array of probabilities of each value in gammas for plotting prior.</span>
<span class="sd">        (1D np.array)</span>

<span class="sd">    prior_weight:</span>
<span class="sd">        An array of probabilities of each value in weights for plotting prior.</span>
<span class="sd">        (1D np.array)</span>

<span class="sd">    gamma_posterior:</span>
<span class="sd">        A 2D array of accepted exponents in each iteration after burn in.</span>
<span class="sd">        Rows - each powerlaw in the mixture.</span>
<span class="sd">        Columns - accepted exponent each iteration.</span>
<span class="sd">        (2D np.array)</span>

<span class="sd">    weight_posterior:</span>
<span class="sd">        A 2D array of accepted weights in each iteration after burn in.</span>
<span class="sd">        Rows - each powerlaw in the mixture.</span>
<span class="sd">        Columns - accepted weight each iteration.</span>
<span class="sd">        (2D np.array)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">data</span><span class="p">,</span>
                 <span class="n">gamma_range</span><span class="o">=</span><span class="p">[</span><span class="mf">1.01</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">],</span>
                 <span class="n">xmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">xmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">discrete</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">niters</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span>
                 <span class="n">sigma</span><span class="o">=</span><span class="p">[</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">],</span>
                 <span class="n">sigma_burn</span><span class="o">=</span><span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span>
                 <span class="n">burn_in</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
                 <span class="n">prior</span><span class="o">=</span><span class="s1">&#39;jeffrey&#39;</span><span class="p">,</span>
                 <span class="n">mixed</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                 <span class="n">fit</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>

        <span class="c1">#convert data to numpy array in case input is a list.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="c1">#xmin</span>
        <span class="k">if</span> <span class="n">xmin</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">xmin</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">xmin</span> <span class="o">=</span> <span class="n">xmin</span>

        <span class="c1">#xmax</span>
        <span class="k">if</span> <span class="n">xmax</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">xmax</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span> <span class="o">+</span> <span class="mf">10.0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">xmax</span> <span class="o">=</span> <span class="n">xmax</span>

        <span class="c1">#filter data given xmin and xmax</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmin</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmax</span> <span class="o">!=</span> <span class="n">np</span><span class="o">.</span><span class="n">infty</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmin</span><span class="p">)</span>
                                  <span class="o">&amp;</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmax</span><span class="p">)]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>  <span class="c1"># length of data array</span>
        <span class="c1"># number of powerlaws in data arranged in the array from 1 to mixed</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mixed</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">mixed</span><span class="p">)</span>
        <span class="c1"># total number of parameters fitted (number of exponents + number of weights where the last weight is equal to 1-[weights])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="n">mixed</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">range</span> <span class="o">=</span> <span class="n">gamma_range</span>  <span class="c1"># exponent range</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">discrete</span> <span class="o">=</span> <span class="n">discrete</span>  <span class="c1"># is data discrete or continuous</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prior_model</span> <span class="o">=</span> <span class="n">prior</span>  <span class="c1"># prior used (jeffrey&#39;s (default) or flat)</span>
        <span class="c1"># number of iterations in MCMC scaled given number of parameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">niters</span> <span class="o">=</span> <span class="n">niters</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
        <span class="c1"># standard deviation of gamma step size in MCMC</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sigma_g</span> <span class="o">=</span> <span class="n">sigma</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="c1"># standard deviation of weight step size in MCMC</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sigma_w</span> <span class="o">=</span> <span class="n">sigma</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="c1"># standard deviation of gamma step size in burn in</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sigma_burn_g</span> <span class="o">=</span> <span class="n">sigma_burn</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="c1"># standard deviation of weight step size in burn in</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sigma_burn_w</span> <span class="o">=</span> <span class="n">sigma_burn</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="c1"># number of iterations in MCMC burn in scaled given number of parameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">burn</span> <span class="o">=</span> <span class="n">burn_in</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>

        <span class="c1"># make array of possible gammas, given the gamma_range, and an array of possible weights.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gammas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">1.01</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">range</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">10000</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.001</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">prior_model</span> <span class="o">==</span> <span class="s1">&#39;jeffrey&#39;</span><span class="p">:</span>
            <span class="c1">#make array of prior function given the jeffrey&#39;s prior.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">prior_gamma</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">Z_jeffrey</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">gammas</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1">#make array of prior function given the flat prior.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">prior_gamma</span> <span class="o">=</span> <span class="p">(</span><span class="n">sp</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">range</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">range</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">range</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gammas</span><span class="p">)</span>

        <span class="c1">#make array of prior function for weights (flat prior).</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prior_weight</span> <span class="o">=</span> <span class="p">(</span><span class="n">sp</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">fit</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">gamma_posterior</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight_posterior</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">posterior</span><span class="p">()</span>

<div class="viewcode-block" id="bayes.Z"><a class="viewcode-back" href="../documentation.html#BayesPowerlaw.bayes.Z">[docs]</a>    <span class="k">def</span> <span class="nf">Z</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gamma</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Partition function Z for discrete and continuous powerlaw distributions.</span>

<span class="sd">        parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        gamma: (float)</span>
<span class="sd">            Randomly sampled target exponent.</span>

<span class="sd">        returns</span>
<span class="sd">        ------</span>
<span class="sd">        s:</span>
<span class="sd">            Partition value.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">discrete</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>  <span class="c1"># when powerlaw is discrete</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xmax</span><span class="p">):</span>  <span class="c1"># if xmax is NOT infinity:</span>
                <span class="c1">#Calculate zeta from Xmin to Infinity and substract Zeta from Xmax to Infinity</span>
                <span class="c1">#To find zeta from Xmin to Xmax.</span>
                <span class="n">s</span> <span class="o">=</span> <span class="n">zeta</span><span class="p">(</span><span class="n">gamma</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmin</span><span class="p">)</span> <span class="o">-</span> <span class="n">zeta</span><span class="p">(</span><span class="n">gamma</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmax</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1">#if xmax is infinity, simply calculate zeta from Xmin till infinity.</span>
                <span class="n">s</span> <span class="o">=</span> <span class="n">zeta</span><span class="p">(</span><span class="n">gamma</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmin</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1">#calculate normalization function when powerlaw is continuous.</span>
            <span class="c1">#s=(xmax^(-gamma+1)/(1-gamma))-(xminx^(-gamma+1)/(1-gamma))</span>
            <span class="n">s</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xmax</span><span class="o">**</span><span class="p">(</span><span class="o">-</span><span class="n">gamma</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">gamma</span><span class="p">))</span> <span class="o">-</span> \
                <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xmin</span><span class="o">**</span><span class="p">(</span><span class="o">-</span><span class="n">gamma</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">gamma</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">s</span></div>

<div class="viewcode-block" id="bayes.Z_prime"><a class="viewcode-back" href="../documentation.html#BayesPowerlaw.bayes.Z_prime">[docs]</a>    <span class="k">def</span> <span class="nf">Z_prime</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gamma</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This function calculates first differential of partition function Z.</span>

<span class="sd">        parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        gamma: (float)</span>
<span class="sd">            Randomly sampled target exponent.</span>

<span class="sd">        returns</span>
<span class="sd">        ------</span>
<span class="sd">        First differential of the Z function.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">h</span> <span class="o">=</span> <span class="mf">1e-8</span>
        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Z</span><span class="p">(</span><span class="n">gamma</span> <span class="o">+</span> <span class="n">h</span><span class="p">)</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">Z</span><span class="p">(</span><span class="n">gamma</span> <span class="o">-</span> <span class="n">h</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">h</span><span class="p">)</span></div>

<div class="viewcode-block" id="bayes.Z_prime2"><a class="viewcode-back" href="../documentation.html#BayesPowerlaw.bayes.Z_prime2">[docs]</a>    <span class="k">def</span> <span class="nf">Z_prime2</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gamma</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This function calculates second differential of partition function Z.</span>

<span class="sd">        parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        gamma: (float)</span>
<span class="sd">            Randomly sampled target exponent.</span>

<span class="sd">        returns</span>
<span class="sd">        ------</span>
<span class="sd">        Second differential of the Z function.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">h</span> <span class="o">=</span> <span class="mf">1e-4</span>
        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Z</span><span class="p">(</span><span class="n">gamma</span> <span class="o">+</span> <span class="n">h</span><span class="p">)</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">Z</span><span class="p">(</span><span class="n">gamma</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">Z</span><span class="p">(</span><span class="n">gamma</span> <span class="o">-</span> <span class="n">h</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="n">h</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span></div>

<div class="viewcode-block" id="bayes.Z_jeffrey"><a class="viewcode-back" href="../documentation.html#BayesPowerlaw.bayes.Z_jeffrey">[docs]</a>    <span class="k">def</span> <span class="nf">Z_jeffrey</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gamma</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This function calculates Jeffrey&#39;s prior for a given exponent.</span>

<span class="sd">        parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        gamma: (float)</span>
<span class="sd">            Randomly sampled target exponent.</span>

<span class="sd">        returns</span>
<span class="sd">        ------</span>
<span class="sd">        Calculated Jeffrey&#39;s prior.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">Z_prime2</span><span class="p">(</span><span class="n">gamma</span><span class="p">))</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">Z</span><span class="p">(</span><span class="n">gamma</span><span class="p">)</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">Z_prime</span><span class="p">(</span><span class="n">gamma</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">Z</span><span class="p">(</span><span class="n">gamma</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span></div>

<div class="viewcode-block" id="bayes.log_prior"><a class="viewcode-back" href="../documentation.html#BayesPowerlaw.bayes.log_prior">[docs]</a>    <span class="k">def</span> <span class="nf">log_prior</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gamma</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This function calculates prior given target exponent and prior model.</span>

<span class="sd">        parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        gamma: (float)</span>
<span class="sd">            Randomly sampled target exponent.</span>

<span class="sd">        returns</span>
<span class="sd">        -------</span>
<span class="sd">        prior_answer: </span>
<span class="sd">            calculated log of prior.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">prior_model</span> <span class="o">==</span> <span class="s1">&#39;jeffrey&#39;</span><span class="p">:</span>
            <span class="c1">#Calculate log of jeffrey&#39;s prior</span>
            <span class="n">prior_answer</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Z_jeffrey</span><span class="p">(</span><span class="n">gamma</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1">#Flat prior: prior=1/(b-a)</span>
            <span class="n">prior_answer</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span>
                <span class="p">(</span><span class="n">sp</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">range</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">range</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">range</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">gamma</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">prior_answer</span></div>

<div class="viewcode-block" id="bayes.weight_prior"><a class="viewcode-back" href="../documentation.html#BayesPowerlaw.bayes.weight_prior">[docs]</a>    <span class="k">def</span> <span class="nf">weight_prior</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This function calculates prior given target weight and flat prior.</span>

<span class="sd">        parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        gamma: (float)</span>
<span class="sd">            Randomly sampled target weight.</span>

<span class="sd">        returns</span>
<span class="sd">        -------</span>
<span class="sd">        prior_answer: </span>
<span class="sd">            calculated log of prior.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">prior_answer</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span>
            <span class="p">(</span><span class="n">sp</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">weight</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">prior_answer</span></div>

<div class="viewcode-block" id="bayes.L"><a class="viewcode-back" href="../documentation.html#BayesPowerlaw.bayes.L">[docs]</a>    <span class="k">def</span> <span class="nf">L</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gamma_params</span><span class="p">,</span> <span class="n">weight_params</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This function calculates the log likelihood given target exponent and weight values.</span>

<span class="sd">        parameters</span>
<span class="sd">        ----------</span>

<span class="sd">        gamma_params: (1D np.array)</span>
<span class="sd">            Array of randomly sampled target exponents for each powerlaw in the data.</span>

<span class="sd">        weight_params: (1D np.array)</span>
<span class="sd">            Array of randomly sampled target weights for each powerlaw in the data.</span>

<span class="sd">        returns</span>
<span class="sd">        -------</span>
<span class="sd">        Calculated log likelihood value.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">lik</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mixed</span><span class="p">)):</span>
            <span class="n">l</span> <span class="o">=</span> <span class="p">(</span><span class="n">weight_params</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">**</span>
                 <span class="p">(</span><span class="o">-</span><span class="n">gamma_params</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">Z</span><span class="p">(</span><span class="n">gamma_params</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="n">lik</span> <span class="o">=</span> <span class="n">lik</span> <span class="o">+</span> <span class="n">l</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">lik</span><span class="p">))</span></div>

<div class="viewcode-block" id="bayes.target"><a class="viewcode-back" href="../documentation.html#BayesPowerlaw.bayes.target">[docs]</a>    <span class="k">def</span> <span class="nf">target</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gamma_params</span><span class="p">,</span> <span class="n">weight_params</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This function calculates target values for comparing existing exponents and weight to</span>
<span class="sd">        newly samples exponents and weights. Target for given parameters is equal to</span>
<span class="sd">        log of (likelihood x prior).</span>

<span class="sd">        parameters</span>
<span class="sd">        ----------</span>

<span class="sd">        gamma_params: (1D np.array)</span>
<span class="sd">            Array of randomly sampled target exponents for each powerlaw in the data.</span>

<span class="sd">        weight_params: (1D np.array)</span>
<span class="sd">            Array of randomly sampled target weights for each powerlaw in the data.</span>

<span class="sd">        returns</span>
<span class="sd">        -------</span>

<span class="sd">        p: </span>
<span class="sd">            calculated target value.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">p</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">gamma_params</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">range</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">gamma_params</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">range</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">weight_params</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">):</span>
            <span class="n">p</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">prior</span><span class="o">=</span><span class="mi">0</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">gamma_params</span><span class="p">)):</span>
                <span class="n">prior</span> <span class="o">=</span> <span class="n">prior</span> <span class="o">+</span> \
                    <span class="bp">self</span><span class="o">.</span><span class="n">log_prior</span><span class="p">(</span><span class="n">gamma_params</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">+</span> \
                    <span class="bp">self</span><span class="o">.</span><span class="n">weight_prior</span><span class="p">(</span><span class="n">weight_params</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">L</span><span class="p">(</span><span class="n">gamma_params</span><span class="p">,</span> <span class="n">weight_params</span><span class="p">)</span> <span class="o">+</span> <span class="n">prior</span>
        <span class="k">return</span> <span class="n">p</span></div>

<div class="viewcode-block" id="bayes.sample_new"><a class="viewcode-back" href="../documentation.html#BayesPowerlaw.bayes.sample_new">[docs]</a>    <span class="k">def</span> <span class="nf">sample_new</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gamma_params</span><span class="p">,</span> <span class="n">weight_params</span><span class="p">,</span> <span class="n">sigma_g</span><span class="p">,</span> <span class="n">sigma_w</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This function performs random sampling of gammas and weights given the initial</span>
<span class="sd">        gamma and weight values.</span>

<span class="sd">        parameters</span>
<span class="sd">        ----------</span>

<span class="sd">        gamma_params: (1D np.array)</span>
<span class="sd">            Array of randomly sampled target exponents for each powerlaw in the data.</span>

<span class="sd">        weight_params: (1D np.array)</span>
<span class="sd">            Array of randomly sampled target weights for each powerlaw in the data.</span>

<span class="sd">        sigma_g: (float&gt;0)</span>
<span class="sd">            Standard deviation of the sampling step size during MCMC for gamma.</span>

<span class="sd">        sigma_w: (float&gt;0)</span>
<span class="sd">            Standard deviation of the sampling step size during MCMC for weights.</span>

<span class="sd">        returns</span>
<span class="sd">        -------</span>

<span class="sd">        gamma_params_p: </span>
<span class="sd">            a 1D array of newly sampled exponent values.</span>
<span class="sd">        </span>
<span class="sd">        weight_params_p:</span>
<span class="sd">            a 1D array of newly sampled weight values.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">gamma_params_p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mixed</span><span class="p">))</span>
        <span class="n">weight_params_p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mixed</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mixed</span><span class="p">)):</span>
            <span class="n">gamma_params_p</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">gamma_params</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> \
                <span class="n">sp</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma_g</span><span class="p">)</span><span class="o">.</span><span class="n">rvs</span><span class="p">()</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mixed</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">weight_params_p</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">weight_params</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> \
                    <span class="n">sp</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma_w</span><span class="p">)</span><span class="o">.</span><span class="n">rvs</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">weight_params_p</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">weight_params</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">weight_params_p</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">weight_params_p</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">gamma_params_p</span><span class="p">,</span> <span class="n">weight_params_p</span></div>

<div class="viewcode-block" id="bayes.random_walk"><a class="viewcode-back" href="../documentation.html#BayesPowerlaw.bayes.random_walk">[docs]</a>    <span class="k">def</span> <span class="nf">random_walk</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gamma_params</span><span class="p">,</span> <span class="n">weight_params</span><span class="p">,</span> <span class="n">sigma_g</span><span class="p">,</span> <span class="n">sigma_w</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This function samples new target exponent and weight values using sample_new function</span>
<span class="sd">        and calculates acceptance values to compare the initial parameter values to the </span>
<span class="sd">        newly sampled ones.</span>

<span class="sd">        parameters</span>
<span class="sd">        ----------</span>

<span class="sd">        gamma_params: (1D np.array)</span>
<span class="sd">            Array of randomly sampled target exponents for each powerlaw in the data.</span>

<span class="sd">        weight_params: (1D np.array)</span>
<span class="sd">            Array of randomly sampled target weights for each powerlaw in the data.</span>

<span class="sd">        sigma_g: (float&gt;0)</span>
<span class="sd">            Standard deviation of gamma step size during random sampling.</span>

<span class="sd">        sigma_w: (float&gt;0)</span>
<span class="sd">            Standard deviation of weight step size during random sampling.</span>

<span class="sd">        returns</span>
<span class="sd">        -------</span>

<span class="sd">        a: </span>
<span class="sd">            acceptance value to compare which parameter values are more likely to result in</span>
<span class="sd">            a more accurate fit.</span>

<span class="sd">        gamma_params_p:</span>
<span class="sd">            1D array of randomly sampled exponents.</span>

<span class="sd">        weight_params_p:</span>
<span class="sd">            1D array of randomly sampled weights.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">gamma_params_p</span><span class="p">,</span> <span class="n">weight_params_p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_new</span><span class="p">(</span>
            <span class="n">gamma_params</span><span class="p">,</span> <span class="n">weight_params</span><span class="p">,</span> <span class="n">sigma_g</span><span class="p">,</span> <span class="n">sigma_w</span><span class="p">)</span>
        <span class="n">target_p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="p">(</span><span class="n">gamma_params_p</span><span class="p">,</span> <span class="n">weight_params_p</span><span class="p">)</span>
        <span class="n">target</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="p">(</span><span class="n">gamma_params</span><span class="p">,</span> <span class="n">weight_params</span><span class="p">)</span>
        <span class="n">a</span> <span class="o">=</span> <span class="o">-</span><span class="mi">10</span><span class="o">**</span><span class="mi">8</span>
        <span class="k">if</span> <span class="n">target_p</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">a</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">target_p</span> <span class="o">-</span> <span class="n">target</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">a</span><span class="p">,</span> <span class="n">gamma_params_p</span><span class="p">,</span> <span class="n">weight_params_p</span></div>

<div class="viewcode-block" id="bayes.burn_in"><a class="viewcode-back" href="../documentation.html#BayesPowerlaw.bayes.burn_in">[docs]</a>    <span class="k">def</span> <span class="nf">burn_in</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gamma_params</span><span class="p">,</span> <span class="n">weight_params</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This function preforms the burn in part of the MCMC algorithm that will get the </span>
<span class="sd">        initial values to the roughly correct range for fitting. The parameters accepted</span>
<span class="sd">        during burn in are not included in the final samples array.</span>

<span class="sd">        parameters</span>
<span class="sd">        ----------</span>

<span class="sd">        gamma_params: (1D np.array)</span>
<span class="sd">            Array of randomly sampled target exponents for each powerlaw in the data.</span>

<span class="sd">        weight_params: (1D np.array)</span>
<span class="sd">            Array of randomly sampled target weights for each powerlaw in the data.</span>


<span class="sd">        returns</span>
<span class="sd">        -------</span>

<span class="sd">        gamma_params:</span>
<span class="sd">            1D array of accepted exponent values.</span>

<span class="sd">        weight_params:</span>
<span class="sd">            1D array of accepted weight values.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">a</span><span class="p">,</span> <span class="n">gamma_params_p</span><span class="p">,</span> <span class="n">weight_params_p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">random_walk</span><span class="p">(</span>
            <span class="n">gamma_params</span><span class="p">,</span> <span class="n">weight_params</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigma_burn_g</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigma_burn_w</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">a</span> <span class="o">==</span> <span class="mf">0.0</span><span class="p">:</span>
            <span class="n">gamma_params</span> <span class="o">=</span> <span class="n">gamma_params_p</span>
            <span class="n">weight_params</span> <span class="o">=</span> <span class="n">weight_params_p</span>
        <span class="k">return</span> <span class="n">gamma_params</span><span class="p">,</span> <span class="n">weight_params</span></div>

<div class="viewcode-block" id="bayes.monte_carlo"><a class="viewcode-back" href="../documentation.html#BayesPowerlaw.bayes.monte_carlo">[docs]</a>    <span class="k">def</span> <span class="nf">monte_carlo</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gamma_params</span><span class="p">,</span> <span class="n">weight_params</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This function preforms the full MCMC algorithm. The parameters accepted in this part</span>
<span class="sd">        of MCMC will be saved in the final samples array.</span>

<span class="sd">        parameters</span>
<span class="sd">        ----------</span>

<span class="sd">        gamma_params: (1D np.array)</span>
<span class="sd">            Array of randomly sampled target exponents for each powerlaw in the data.</span>

<span class="sd">        weight_params: (1D np.array)</span>
<span class="sd">            Array of randomly sampled target weights for each powerlaw in the data.</span>


<span class="sd">        returns</span>
<span class="sd">        -------</span>

<span class="sd">        gamma_params:</span>
<span class="sd">            1D array of accepted exponent values.</span>

<span class="sd">        weight_params:</span>
<span class="sd">            1D array of accepted weight values.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">a</span><span class="p">,</span> <span class="n">gamma_params_p</span><span class="p">,</span> <span class="n">weight_params_p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">random_walk</span><span class="p">(</span>
            <span class="n">gamma_params</span><span class="p">,</span> <span class="n">weight_params</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigma_g</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigma_w</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">a</span> <span class="o">&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)):</span>
            <span class="n">gamma_params</span> <span class="o">=</span> <span class="n">gamma_params_p</span>
            <span class="n">weight_params</span> <span class="o">=</span> <span class="n">weight_params_p</span>
        <span class="k">return</span> <span class="n">gamma_params</span><span class="p">,</span> <span class="n">weight_params</span></div>

<div class="viewcode-block" id="bayes.posterior"><a class="viewcode-back" href="../documentation.html#BayesPowerlaw.bayes.posterior">[docs]</a>    <span class="k">def</span> <span class="nf">posterior</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        A master function that executes burn in and monte carlo algorithms while</span>
<span class="sd">        storing the accepted parameter values into the final samples array.</span>

<span class="sd">        parameters</span>
<span class="sd">        ----------</span>

<span class="sd">        None.</span>

<span class="sd">        returns</span>
<span class="sd">        -------</span>

<span class="sd">        samples_gamma:</span>
<span class="sd">            A 2D array of accepted exponents in each iteration after burn in.</span>
<span class="sd">            Rows - each powerlaw in the mixture.</span>
<span class="sd">            Columns - accepted exponent each iteration.</span>

<span class="sd">        samples_weight:</span>
<span class="sd">            A 2D array of accepted weights in each iteration after burn in.</span>
<span class="sd">            Rows - each powerlaw in the mixture.</span>
<span class="sd">            Columns - accepted weight each iteration.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">gamma_params</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">range</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">*</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mixed</span><span class="p">)))</span>
        <span class="n">weight_params</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mixed</span><span class="p">)]</span> <span class="o">*</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mixed</span><span class="p">)))</span>
        <span class="c1">#perform a burn in first without recording gamma values</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">burn</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">gamma_params</span><span class="p">,</span> <span class="n">weight_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">burn_in</span><span class="p">(</span>
                <span class="n">gamma_params</span><span class="p">,</span> <span class="n">weight_params</span><span class="p">)</span>
        <span class="c1">#now perform the rest of the sampling while recording gamma values</span>
        <span class="n">samples_gamma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mixed</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">niters</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span>
        <span class="n">samples_gamma</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">gamma_params</span>
        <span class="n">samples_weight</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mixed</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">niters</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span>
        <span class="n">samples_weight</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">weight_params</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">niters</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">gamma_params</span><span class="p">,</span> <span class="n">weight_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">monte_carlo</span><span class="p">(</span>
                <span class="n">gamma_params</span><span class="p">,</span> <span class="n">weight_params</span><span class="p">)</span>
            <span class="n">samples_gamma</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">gamma_params</span>
            <span class="n">samples_weight</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">weight_params</span>
        <span class="k">return</span> <span class="n">samples_gamma</span><span class="p">,</span> <span class="n">samples_weight</span></div>

<div class="viewcode-block" id="bayes.bic"><a class="viewcode-back" href="../documentation.html#BayesPowerlaw.bayes.bic">[docs]</a>    <span class="k">def</span> <span class="nf">bic</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">samples_gamma</span><span class="p">,</span> <span class="n">samples_weight</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This function calculates the Beyesian Information Criteria for</span>
<span class="sd">        determining the number of parameters most optimal for fittin the dataset.</span>

<span class="sd">        parameters</span>
<span class="sd">        ----------</span>

<span class="sd">        samples_gamma: (2D np.array)</span>
<span class="sd">            accepted exponents in each iteration after burn in.</span>
<span class="sd">            Rows - each powerlaw in the mixture.</span>
<span class="sd">            Columns - accepted exponent each iteration.</span>

<span class="sd">        samples_weight: (2D np.array)</span>
<span class="sd">            accepted weights in each iteration after burn in.</span>
<span class="sd">            Rows - each powerlaw in the mixture.</span>
<span class="sd">            Columns - accepted weight each iteration.</span>

<span class="sd">        returns</span>
<span class="sd">        -------</span>

<span class="sd">        b:</span>
<span class="sd">            Beyesian Information Criteria (BIC) value.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">gamma_params</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">samples_gamma</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">weight_params</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">samples_weight</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mixed</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-</span> \
            <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">L</span><span class="p">(</span><span class="n">gamma_params</span><span class="p">,</span> <span class="n">weight_params</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">b</span></div>

<div class="viewcode-block" id="bayes.powerlawpdf"><a class="viewcode-back" href="../documentation.html#BayesPowerlaw.bayes.powerlawpdf">[docs]</a>    <span class="k">def</span> <span class="nf">powerlawpdf</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">final_gamma</span><span class="p">,</span> <span class="n">xmin</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The power law probability function for generating the best fit curve.</span>

<span class="sd">        parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        final_gamma: (float)</span>
<span class="sd">            Final exponent used to generate the best fit curve. For best results</span>
<span class="sd">            use the mean of posterior samples.</span>

<span class="sd">        returns</span>
<span class="sd">        -------</span>
<span class="sd">        xp: (1D array)</span>
<span class="sd">            array of X&#39;s arranged from xmin to xmax of the data.</span>

<span class="sd">        yp: (1D array)</span>
<span class="sd">            array of probabilities for each X given the final exponent.</span>
<span class="sd">        </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">xmin</span> <span class="o">==</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">xmin</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmin</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">discrete</span><span class="p">:</span>
            <span class="n">xp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">xmin</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmax</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">xp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">xmin</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmax</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
        <span class="n">yp</span> <span class="o">=</span> <span class="p">(</span><span class="n">xp</span><span class="o">**</span><span class="p">(</span><span class="o">-</span><span class="n">final_gamma</span><span class="p">))</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">Z</span><span class="p">(</span><span class="n">final_gamma</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">xp</span><span class="p">,</span> <span class="n">yp</span></div>

<div class="viewcode-block" id="bayes.plot_fit"><a class="viewcode-back" href="../documentation.html#BayesPowerlaw.bayes.plot_fit">[docs]</a>    <span class="k">def</span> <span class="nf">plot_fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">gamma_mean</span><span class="p">,</span>
                 <span class="n">label</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">data_color</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">edge_color</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">fit_color</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">scatter_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                 <span class="n">line_width</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                 <span class="n">fit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">log</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">xmin</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Function for plotting the date as a power law distribution on a log log scale</span>
<span class="sd">        along with the best fit.</span>

<span class="sd">        parameters</span>
<span class="sd">        ----------</span>

<span class="sd">        gamma_mean: (float)</span>
<span class="sd">            Final exponent used to generate the best fit curve. For best results</span>
<span class="sd">            use the mean of posterior samples.</span>

<span class="sd">        label: (str)</span>
<span class="sd">            curve label.</span>

<span class="sd">        data color: (str)</span>
<span class="sd">            color of the data scatter plot.</span>

<span class="sd">        edge_color: (str)</span>
<span class="sd">            color of the scatter marker edge.</span>

<span class="sd">        fit_color: (str)</span>
<span class="sd">            color of the best fit curve.</span>
<span class="sd">        </span>
<span class="sd">        scatter_size: (int or float)</span>
<span class="sd">            scatter marker size.</span>

<span class="sd">        line_width: (int or float)</span>
<span class="sd">            width of the best fit curve.</span>

<span class="sd">        fit: (bool)</span>
<span class="sd">            Whether to plot the best fit curve or not (default True).</span>

<span class="sd">        log: (bool)</span>
<span class="sd">            Whether to plot in the log scale or not (default True).</span>

<span class="sd">        returns</span>
<span class="sd">        -------</span>

<span class="sd">        None.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">discrete</span><span class="p">:</span>
            <span class="n">unique</span><span class="p">,</span> <span class="n">counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">frequency</span> <span class="o">=</span> <span class="n">counts</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">counts</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">yx</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">normed</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">clf</span><span class="p">()</span>
            <span class="n">counts_pre</span> <span class="o">=</span> <span class="p">(</span><span class="n">yx</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="n">unique_pre</span> <span class="o">=</span> <span class="p">((</span><span class="n">yx</span><span class="p">[</span><span class="mi">1</span><span class="p">])[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">unique</span> <span class="o">=</span> <span class="n">unique_pre</span><span class="p">[</span><span class="n">counts_pre</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">]</span>
            <span class="n">frequency</span> <span class="o">=</span> <span class="n">counts_pre</span><span class="p">[</span><span class="n">counts_pre</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">]</span>
            <span class="c1"># frequency = counts / np.sum(counts)</span>

        <span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">powerlawpdf</span><span class="p">(</span><span class="n">gamma_mean</span><span class="p">,</span> <span class="n">xmin</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">xscale</span><span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">yscale</span><span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">unique</span><span class="p">,</span> <span class="n">frequency</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">scatter_size</span><span class="p">,</span>
                    <span class="n">color</span><span class="o">=</span><span class="n">data_color</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="n">edge_color</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">fit</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">fit_color</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="n">line_width</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">)</span>

        <span class="k">return</span></div>

<div class="viewcode-block" id="bayes.plot_prior"><a class="viewcode-back" href="../documentation.html#BayesPowerlaw.bayes.plot_prior">[docs]</a>    <span class="k">def</span> <span class="nf">plot_prior</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Function for plotting prior for gammas.</span>

<span class="sd">        parameters</span>
<span class="sd">        ----------</span>

<span class="sd">        color: (str)</span>
<span class="sd">            color of the curve</span>
<span class="sd">        </span>
<span class="sd">        label: (str)</span>
<span class="sd">            label of the curve</span>

<span class="sd">        returns</span>
<span class="sd">        -------</span>

<span class="sd">        None.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gammas</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">prior_gamma</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">)</span>
        <span class="k">return</span></div>

<div class="viewcode-block" id="bayes.plot_posterior"><a class="viewcode-back" href="../documentation.html#BayesPowerlaw.bayes.plot_posterior">[docs]</a>    <span class="k">def</span> <span class="nf">plot_posterior</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">samples</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">normed</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Function for plotting posterior histogram.</span>

<span class="sd">        parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        samples: (1D array)</span>
<span class="sd">            an array of accepted exponents during the MCMC algorithm.</span>
<span class="sd">        </span>
<span class="sd">        bins: (int)</span>
<span class="sd">            number of bins used for the histogram (default: 100).</span>
<span class="sd">        </span>
<span class="sd">        alpha: (0&lt;=float&lt;=1)</span>
<span class="sd">            transparency of the histogram.</span>

<span class="sd">        color: (str)</span>
<span class="sd">            color of the histogram.</span>
<span class="sd">        </span>
<span class="sd">        label: (str)</span>
<span class="sd">            label of the histogram.</span>
<span class="sd">        </span>
<span class="sd">        range: (tuple)</span>
<span class="sd">            range of histogram&#39;s X axis.</span>
<span class="sd">        </span>
<span class="sd">        normed: (bool)</span>
<span class="sd">            whether the histogram is normalized or not (default: True)</span>

<span class="sd">        returns</span>
<span class="sd">        -------</span>

<span class="sd">        None.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">bins</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span>
                 <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="nb">range</span><span class="p">,</span> <span class="n">normed</span><span class="o">=</span><span class="n">normed</span><span class="p">)</span>
        <span class="k">return</span></div></div>


<div class="viewcode-block" id="maxLikelihood"><a class="viewcode-back" href="../documentation.html#BayesPowerlaw.maxLikelihood">[docs]</a><span class="k">class</span> <span class="nc">maxLikelihood</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;This function fits the data to powerlaw distribution and outputs the exponent</span>
<span class="sd">    using the maximum likelihood and Newton-Raphson approach.</span>

<span class="sd">    parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data: (list or np.array of numbers)</span>
<span class="sd">        An array of data from the powerlaw that is being fitted here y=x^(-gamma)/Z.</span>
<span class="sd">        All values must be integers or floats from 1 to infinity.</span>

<span class="sd">    initial_guess: (list [lower range&gt;=1, upper range, number of initial guesses])</span>
<span class="sd">        a list for generating a 1D array containing a variation of initial guesses for </span>
<span class="sd">        Newton-Raphson algorithm.</span>

<span class="sd">    min: (int or float &gt;=1)</span>
<span class="sd">        The lowest value from the data included in the powerlaw fit. </span>
<span class="sd">        Default value is &quot;None&quot;, in which case the minimum value observed in the data is used.</span>
<span class="sd">    </span>
<span class="sd">    xmax: (int or float &gt;= xmin)</span>
<span class="sd">        The highest value from the data included in the powerlaw fit. </span>
<span class="sd">        Default value is &quot;None&quot;, in which case the maximum value observed in the data is used.</span>
<span class="sd">        To set xmax to infinity use xmax=np.infty.</span>
<span class="sd">    </span>
<span class="sd">    discrete: (bool) </span>
<span class="sd">        Whether or not the powerlaw is discrete or continuous.</span>
<span class="sd">        Default True, in which case powerlaw is assumed to be discrete.</span>
<span class="sd">        The distinction is important when estimating partition function Z.    </span>

<span class="sd">    attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    </span>
<span class="sd">    n: </span>
<span class="sd">        Sample size of the data.</span>
<span class="sd">        (int&gt;5)</span>

<span class="sd">    constant:</span>
<span class="sd">        a constant calculated to be added to 1st order Z differential prior to</span>
<span class="sd">        preforming Newton-Raphson algorithm.</span>
<span class="sd">        (float)</span>

<span class="sd">    initial_guess:</span>
<span class="sd">        an array of initial guesses used in Newton-Raphson algorithm.</span>
<span class="sd">        (1D array)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">data</span><span class="p">,</span>
                 <span class="n">initial_guess</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span>
                 <span class="n">xmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">xmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">discrete</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="c1">#xmin</span>
        <span class="k">if</span> <span class="n">xmin</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">xmin</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">xmin</span> <span class="o">=</span> <span class="n">xmin</span>

        <span class="k">if</span> <span class="n">xmax</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">xmax</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span> <span class="o">+</span> <span class="mf">10.0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">xmax</span> <span class="o">=</span> <span class="n">xmax</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmin</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmax</span> <span class="o">!=</span> <span class="n">np</span><span class="o">.</span><span class="n">infty</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmin</span><span class="p">)</span>
                                  <span class="o">&amp;</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmax</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">constant</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">))</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">n</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">discrete</span> <span class="o">=</span> <span class="n">discrete</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">initial_guess</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span>
            <span class="n">initial_guess</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">initial_guess</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">initial_guess</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>

<div class="viewcode-block" id="maxLikelihood.Z"><a class="viewcode-back" href="../documentation.html#BayesPowerlaw.maxLikelihood.Z">[docs]</a>    <span class="k">def</span> <span class="nf">Z</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gamma</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Partition function Z for discrete and continuous powerlaw distributions.</span>

<span class="sd">        parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        gamma: (float)</span>
<span class="sd">            exponent guess.</span>

<span class="sd">        returns</span>
<span class="sd">        ------</span>
<span class="sd">        s:</span>
<span class="sd">            Partition value.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">discrete</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>  <span class="c1"># when powerlaw is discrete</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xmax</span><span class="p">):</span>  <span class="c1"># if xmax is NOT infinity:</span>
                <span class="c1">#Calculate zeta from Xmin to Infinity and substract Zeta from Xmax to Infinity</span>
                <span class="c1">#To find zeta from Xmin to Xmax.</span>
                <span class="n">s</span> <span class="o">=</span> <span class="n">zeta</span><span class="p">(</span><span class="n">gamma</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmin</span><span class="p">)</span> <span class="o">-</span> <span class="n">zeta</span><span class="p">(</span><span class="n">gamma</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmax</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1">#if xmax is infinity, simply calculate zeta from Xmin till infinity.</span>
                <span class="n">s</span> <span class="o">=</span> <span class="n">zeta</span><span class="p">(</span><span class="n">gamma</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmin</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1">#calculate normalization function when powerlaw is continuous.</span>
            <span class="c1">#s=(xmax^(-gamma+1)/(1-gamma))-(xminx^(-gamma+1)/(1-gamma))</span>
            <span class="n">s</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xmax</span><span class="o">**</span><span class="p">(</span><span class="o">-</span><span class="n">gamma</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">gamma</span><span class="p">))</span> <span class="o">-</span> \
                <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xmin</span><span class="o">**</span><span class="p">(</span><span class="o">-</span><span class="n">gamma</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">gamma</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">s</span></div>

<div class="viewcode-block" id="maxLikelihood.F"><a class="viewcode-back" href="../documentation.html#BayesPowerlaw.maxLikelihood.F">[docs]</a>    <span class="k">def</span> <span class="nf">F</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gamma</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;The optimization function. </span>
<span class="sd">        </span>
<span class="sd">        parameters</span>
<span class="sd">        ----------</span>

<span class="sd">        gamma: (float)</span>
<span class="sd">            exponent guess.</span>

<span class="sd">        returns</span>
<span class="sd">        -------</span>

<span class="sd">            First order Z differential plus constant attribute.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">h</span> <span class="o">=</span> <span class="mf">1e-8</span>
        <span class="n">Z_prime</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Z</span><span class="p">(</span><span class="n">gamma</span> <span class="o">+</span> <span class="n">h</span><span class="p">)</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">Z</span><span class="p">(</span><span class="n">gamma</span> <span class="o">-</span> <span class="n">h</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">h</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">Z_prime</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">Z</span><span class="p">(</span><span class="n">gamma</span><span class="p">))</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">constant</span></div>

<div class="viewcode-block" id="maxLikelihood.Guess"><a class="viewcode-back" href="../documentation.html#BayesPowerlaw.maxLikelihood.Guess">[docs]</a>    <span class="k">def</span> <span class="nf">Guess</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Master function that performs Newton-Raphson algorithm and determins best</span>
<span class="sd">        exponent guess via maximum likelihood.</span>

<span class="sd">        parameters</span>
<span class="sd">        ----------</span>

<span class="sd">        None.</span>

<span class="sd">        returns</span>
<span class="sd">        -------</span>

<span class="sd">        best_guess: (1D array)</span>
<span class="sd">            an array containing best exponent guesses given the maximum likelihood.</span>
<span class="sd">            Length of array will be more than 1 if same likelihood value is associated</span>
<span class="sd">            with more than one exponent guess. </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">best_guess</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">initial_guess</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">initial_guess</span><span class="p">)):</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">best_guess</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">newton</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">F</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">initial_guess</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="k">except</span> <span class="ne">RuntimeError</span><span class="p">:</span>
                <span class="n">best_guess</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">best_guess</span> <span class="o">=</span> <span class="n">best_guess</span><span class="p">[</span><span class="n">best_guess</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">]</span>
        <span class="n">log_likelihood</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">best_guess</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">best_guess</span><span class="p">)):</span>
            <span class="n">log_likelihood</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span> <span class="o">*</span> \
                <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Z</span><span class="p">(</span><span class="n">best_guess</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span> <span class="o">-</span> \
                <span class="n">best_guess</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_likelihood</span> <span class="o">=</span> <span class="n">log_likelihood</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">log_likelihood</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">best_guess</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">best_guess</span> <span class="o">=</span> <span class="n">best_guess</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
                <span class="n">log_likelihood</span> <span class="o">==</span> <span class="nb">max</span><span class="p">(</span><span class="n">log_likelihood</span><span class="p">))]</span>
        <span class="k">return</span> <span class="n">best_guess</span></div></div>



<div class="viewcode-block" id="power_law"><a class="viewcode-back" href="../documentation.html#BayesPowerlaw.power_law">[docs]</a><span class="k">def</span> <span class="nf">power_law</span><span class="p">(</span><span class="n">exponents</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">xmax</span><span class="p">,</span> <span class="n">sample_size</span><span class="p">,</span> <span class="n">xmin</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">discrete</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;This function simulates a dataset that follows a powerlaw</span>
<span class="sd">    distribution with a given exponent and xmax.</span>


<span class="sd">    parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    exponents: (array of floats&gt;1) </span>
<span class="sd">        array of exponents of the mixed powerlaw distribution equation. Array length is equal to the simulated mixture size.</span>
<span class="sd">        e.g. for single power law, array will contain only one value, mixture of 2 - two values, etc.</span>

<span class="sd">    weights: (array of 0&lt;floats&lt;=1) </span>
<span class="sd">        array of weights of the mixed powerlaw distribution equation. Array length is equal to the simulated mixture size.</span>
<span class="sd">        e.g. for single power law, array will contain only one value that will be equal to 1, mixture of 2 - two values, etc.</span>
<span class="sd">        The sum of array must always be equal to 1.</span>

<span class="sd">    xmax: (int or float &gt; xmin)</span>
<span class="sd">        the maximum possible x value in the simulated dataset.</span>

<span class="sd">    sample_size: (int&gt;5)</span>
<span class="sd">        samples size of the simulated dataset.</span>

<span class="sd">    xmin: (int or float &gt;=1)</span>
<span class="sd">        the minimum possible x value in the simulated dataset (default: 1).</span>

<span class="sd">    discrete: (bool) </span>
<span class="sd">        whether the simulated powerlaw contains discrete (True) or continuous (False) values (default: True)</span>
<span class="sd">    </span>
<span class="sd">    returns</span>
<span class="sd">    -------</span>

<span class="sd">    1D array of X&#39;es that has a size of sample_size parameter.</span>
<span class="sd">    </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">discrete</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>
        <span class="c1">#arrange numpy array of number from 1 to xmax+1 in the float format.</span>
    	<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">xmin</span><span class="p">,</span> <span class="n">xmax</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
    	<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">xmin</span><span class="p">,</span> <span class="n">xmax</span><span class="p">,</span> <span class="n">xmax</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    <span class="c1">#plug each value into powerlaw equation to start generating probability mass function (pmf)</span>
    <span class="n">pmf</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">exponents</span><span class="p">)):</span>
        <span class="n">f</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">x</span><span class="o">**</span><span class="n">exponents</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">f</span> <span class="o">/=</span> <span class="n">f</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="n">pmf</span> <span class="o">=</span> <span class="n">pmf</span> <span class="o">+</span> <span class="n">weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">f</span>
    <span class="c1">#np.random.choice function generates a random sample of a given sample size</span>
    <span class="c1">#from a given 1-D array x, given the probabilities for each value.</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">sample_size</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">pmf</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">demo</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Performs a demonstration of BayesPowerlaw.</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    </span>
<span class="sd">    None.</span>

<span class="sd">    Return</span>
<span class="sd">    ------</span>

<span class="sd">    None.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="kn">import</span> <span class="nn">os</span>
    <span class="n">example_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="vm">__file__</span><span class="p">)</span>
    <span class="n">example</span> <span class="o">=</span> <span class="s1">&#39;examples/scripts/tweets.py&#39;</span>
    <span class="n">file_name</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="si">%s</span><span class="s1">/</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">example_dir</span><span class="p">,</span> <span class="n">example</span><span class="p">)</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">content</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
        <span class="n">line</span> <span class="o">=</span> <span class="s1">&#39;-------------------------------------------------------------&#39;</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Running </span><span class="si">%s</span><span class="s1">:</span><span class="se">\n</span><span class="si">%s</span><span class="se">\n</span><span class="si">%s</span><span class="se">\n</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span>
            <span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">line</span><span class="p">,</span> <span class="n">content</span><span class="p">,</span> <span class="n">line</span><span class="p">))</span>
    <span class="n">exec</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="n">file_name</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>
</pre></div>

          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="nav-item nav-item-0"><a href="../index.html">BayesPowerlaw 0.1 documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="index.html" >Module code</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2018, Kristina Grigaityte, Atwal S. Gurinder.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.7.6.
    </div>
  </body>
</html>